---
title: Beyond task diversity - Provable representation transfer for sequential multi-task linear bandits 
layout: post
usemathjax: true
type: article
status: NeurIPS 2024
categories: 
    - bandit
    - meta-learning
    - representation learning
    - reinforcement learning
---

We study lifelong learning in linear bandits, where a learner interacts with a sequence of linear bandit tasks whose parameters lie in an _m_-dimensional subspace of $$\mathbb{R}^d$$, thereby sharing a low-rank representation. Current literature typically assumes that the tasks are _diverse_, i.e., their parameters uniformly span the _m_-dimensional subspace. This assumption allows the low-rank representation to be learned before all tasks are revealed, which can be unrealistic in real-world applications. In this work, we present the first nontrivial result for sequential multi-task linear bandits without the task diversity assumption. We develop an algorithm that efficiently learns and transfers low-rank representations. When facing _N_ tasks, each played over $$\tau$$ rounds, our algorithm achieves a regret guarantee of $$\tilde{O}\big (Nm \sqrt{\tau} + N^{\frac{2}{3}} \tau^{\frac{2}{3}} d m^{\frac13} + Nd^2 + \tau m d \big)$$ under the ellipsoid action set assumption.

Read more: [here]({{ site.baseurl }}/pdfs/neurips24.pdf)
